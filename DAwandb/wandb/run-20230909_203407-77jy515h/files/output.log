Using cpu device
ResNet(
  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=10, bias=True)
)
Epoch 1
-------------------------------
loss: 2.667720  [    0/60000]
/Users/kimkirok/opt/anaconda3/envs/wandb/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/Users/kimkirok/opt/anaconda3/envs/wandb/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)




















 10%|███████████████▌                                                                                                                                        | 96/938 [00:41<06:00,  2.33it/s]






















 21%|████████████████████████████████                                                                                                                       | 199/938 [01:25<05:11,  2.37it/s]






















 32%|███████████████████████████████████████████████▉                                                                                                       | 298/938 [02:09<04:32,  2.35it/s]





















 42%|███████████████████████████████████████████████████████████████▋                                                                                       | 396/938 [02:51<03:56,  2.29it/s]






















 53%|████████████████████████████████████████████████████████████████████████████████▏                                                                      | 498/938 [03:35<03:16,  2.24it/s]





















 64%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                       | 596/938 [04:17<02:24,  2.37it/s]






















 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 699/938 [05:02<01:42,  2.33it/s]





















 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 797/938 [05:44<00:59,  2.36it/s]























 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 898/938 [06:30<00:16,  2.38it/s]








100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [06:47<00:00,  2.30it/s]








 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 149/157 [00:16<00:00,  9.11it/s]
Test Error:
 Accuracy: 79.3%, Avg loss: 0.565142
Epoch 2
-------------------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:17<00:00,  8.89it/s]





















 10%|███████████████▉                                                                                                                                        | 98/938 [00:43<06:07,  2.29it/s]






















 21%|████████████████████████████████▏                                                                                                                      | 200/938 [01:27<05:29,  2.24it/s]





















 32%|███████████████████████████████████████████████▋                                                                                                       | 296/938 [02:09<04:32,  2.36it/s]
























 43%|████████████████████████████████████████████████████████████████▍                                                                                      | 400/938 [02:57<04:48,  1.86it/s]
























 53%|████████████████████████████████████████████████████████████████████████████████                                                                       | 497/938 [03:45<03:12,  2.29it/s]
























 64%|████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 597/938 [04:33<02:51,  1.99it/s]
























 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 699/938 [05:21<02:12,  1.81it/s]



























 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                      | 800/938 [06:16<01:11,  1.92it/s]





























 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 901/938 [07:13<00:25,  1.44it/s]










100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [07:34<00:00,  2.06it/s]








100%|█████████████████████████████████████████████████| 157/157 [00:19<00:00,  8.23it/s]
  0%|                                                           | 0/938 [00:00<?, ?it/s]
Test Error:
 Accuracy: 82.0%, Avg loss: 0.488661
Epoch 3
-------------------------------
























 11%|█████▏                                           | 100/938 [00:48<06:21,  2.20it/s]























 21%|██████████▌                                      | 201/938 [01:34<06:08,  2.00it/s]






















 32%|███████████████▌                                 | 299/938 [02:18<04:40,  2.28it/s]
























 43%|████████████████████▉                            | 401/938 [03:06<04:09,  2.15it/s]























 53%|██████████████████████████                       | 500/938 [03:52<03:15,  2.24it/s]























 64%|███████████████████████████████▍                 | 601/938 [04:38<02:33,  2.20it/s]























 75%|████████████████████████████████████▌            | 700/938 [05:24<01:47,  2.22it/s]






















 85%|█████████████████████████████████████████▋       | 798/938 [06:08<01:07,  2.06it/s]























 96%|██████████████████████████████████████████████▊  | 897/938 [06:54<00:18,  2.21it/s]









100%|█████████████████████████████████████████████████| 938/938 [07:13<00:00,  2.16it/s]








 96%|██████████████████████████████████████████████▊  | 150/157 [00:17<00:00,  8.76it/s]
Test Error:
 Accuracy: 83.2%, Avg loss: 0.454563
Epoch 4
-------------------------------
100%|█████████████████████████████████████████████████| 157/157 [00:18<00:00,  8.70it/s]
























 11%|█████▎                                           | 101/938 [00:49<06:41,  2.09it/s]























 21%|██████████▎                                      | 198/938 [01:35<05:26,  2.27it/s]























 32%|███████████████▋                                 | 300/938 [02:21<05:17,  2.01it/s]























 42%|████████████████████▊                            | 398/938 [03:07<04:13,  2.13it/s]

























 54%|██████████████████████████▏                      | 502/938 [03:57<03:09,  2.30it/s]






















 64%|███████████████████████████████▎                 | 599/938 [04:41<02:30,  2.26it/s]























 74%|████████████████████████████████████▍            | 698/938 [05:27<01:45,  2.27it/s]
























 86%|█████████████████████████████████████████▉       | 802/938 [06:15<01:05,  2.07it/s]























 96%|██████████████████████████████████████████████▉  | 898/938 [07:01<00:18,  2.11it/s]









100%|█████████████████████████████████████████████████| 938/938 [07:20<00:00,  2.13it/s]







100%|█████████████████████████████████████████████████| 157/157 [00:17<00:00,  8.88it/s]
  0%|                                                           | 0/938 [00:00<?, ?it/s]
Test Error:
 Accuracy: 84.2%, Avg loss: 0.437999
Epoch 5
-------------------------------























 10%|█████▏                                            | 98/938 [00:46<07:04,  1.98it/s]
























 21%|██████████▎                                      | 198/938 [01:34<06:08,  2.01it/s]

























 32%|███████████████▋                                 | 301/938 [02:24<04:35,  2.31it/s]























 43%|████████████████████▉                            | 400/938 [03:10<04:03,  2.21it/s]
























 54%|██████████████████████████▏                      | 502/938 [03:58<03:26,  2.12it/s]























 64%|███████████████████████████████▎                 | 600/938 [04:44<02:31,  2.23it/s]






















 74%|████████████████████████████████████▍            | 698/938 [05:28<01:45,  2.28it/s]

























 85%|█████████████████████████████████████████▊       | 800/938 [06:18<01:01,  2.23it/s]

























 96%|███████████████████████████████████████████████  | 901/938 [07:08<00:18,  2.02it/s]









100%|█████████████████████████████████████████████████| 938/938 [07:27<00:00,  2.10it/s]






 97%|███████████████████████████████████████████████▍ | 152/157 [00:19<00:00,  9.16it/s]
Test Error:
 Accuracy: 84.5%, Avg loss: 0.429358
Done!
100%|█████████████████████████████████████████████████| 157/157 [00:20<00:00,  7.81it/s]
/Users/kimkirok/opt/anaconda3/envs/wandb/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/Users/kimkirok/opt/anaconda3/envs/wandb/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "/Users/kimkirok/projects/wandb/DAwandb/main.py", line 194, in <module>
    wandb_logging(opt)
    ^^^^^^
  File "/Users/kimkirok/projects/wandb/DAwandb/main.py", line 190, in main
    print(f'Predicted: "{predicted}", Actual: "{actual}"')
    ^^^^^^^^
  File "/Users/kimkirok/projects/wandb/DAwandb/main.py", line 165, in run
    num_ftrs = model.fc.in_features
  File "/Users/kimkirok/opt/anaconda3/envs/wandb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2041, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "layer1.0.conv3.weight", "layer1.0.bn3.weight", "layer1.0.bn3.bias", "layer1.0.bn3.running_mean", "layer1.0.bn3.running_var", "layer1.0.downsample.0.weight", "layer1.0.downsample.1.weight", "layer1.0.downsample.1.bias", "layer1.0.downsample.1.running_mean", "layer1.0.downsample.1.running_var", "layer1.1.conv3.weight", "layer1.1.bn3.weight", "layer1.1.bn3.bias", "layer1.1.bn3.running_mean", "layer1.1.bn3.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer1.2.conv3.weight", "layer1.2.bn3.weight", "layer1.2.bn3.bias", "layer1.2.bn3.running_mean", "layer1.2.bn3.running_var", "layer2.0.conv3.weight", "layer2.0.bn3.weight", "layer2.0.bn3.bias", "layer2.0.bn3.running_mean", "layer2.0.bn3.running_var", "layer2.1.conv3.weight", "layer2.1.bn3.weight", "layer2.1.bn3.bias", "layer2.1.bn3.running_mean", "layer2.1.bn3.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.2.conv3.weight", "layer2.2.bn3.weight", "layer2.2.bn3.bias", "layer2.2.bn3.running_mean", "layer2.2.bn3.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer2.3.conv3.weight", "layer2.3.bn3.weight", "layer2.3.bn3.bias", "layer2.3.bn3.running_mean", "layer2.3.bn3.running_var", "layer3.0.conv3.weight", "layer3.0.bn3.weight", "layer3.0.bn3.bias", "layer3.0.bn3.running_mean", "layer3.0.bn3.running_var", "layer3.1.conv3.weight", "layer3.1.bn3.weight", "layer3.1.bn3.bias", "layer3.1.bn3.running_mean", "layer3.1.bn3.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.2.conv3.weight", "layer3.2.bn3.weight", "layer3.2.bn3.bias", "layer3.2.bn3.running_mean", "layer3.2.bn3.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.3.conv3.weight", "layer3.3.bn3.weight", "layer3.3.bn3.bias", "layer3.3.bn3.running_mean", "layer3.3.bn3.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.4.conv3.weight", "layer3.4.bn3.weight", "layer3.4.bn3.bias", "layer3.4.bn3.running_mean", "layer3.4.bn3.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer3.5.conv3.weight", "layer3.5.bn3.weight", "layer3.5.bn3.bias", "layer3.5.bn3.running_mean", "layer3.5.bn3.running_var", "layer4.0.conv3.weight", "layer4.0.bn3.weight", "layer4.0.bn3.bias", "layer4.0.bn3.running_mean", "layer4.0.bn3.running_var", "layer4.1.conv3.weight", "layer4.1.bn3.weight", "layer4.1.bn3.bias", "layer4.1.bn3.running_mean", "layer4.1.bn3.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "layer4.2.conv3.weight", "layer4.2.bn3.weight", "layer4.2.bn3.bias", "layer4.2.bn3.running_mean", "layer4.2.bn3.running_var".
	size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).
	size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).
	size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).
	size mismatch for layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).
	size mismatch for layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).
	size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).
	size mismatch for layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).
	size mismatch for layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).
	size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).
	size mismatch for layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).
	size mismatch for layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).
	size mismatch for fc.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([10, 2048]).